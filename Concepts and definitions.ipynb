{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "332f3d8b",
   "metadata": {},
   "source": [
    "#### Large Language Models\n",
    "\n",
    "Language models use probabilistic method to predict the next set of words in a sentence. Gmail autocomplete is one widely used language model application. \n",
    "\n",
    "Large language models are trained on a large set of data from various sources. Large language models have neural network architectures with milllions of parameters. These parameters are capable to capture patterns and nuances of languages. Also, large language models use another technique called Reinforcement Learning with Human Feedback (RLHF). LLMs do not have subjective experience, emotions, or conciousness as human. LLMs works completely based on data that those are trained on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61484d05",
   "metadata": {},
   "source": [
    "#### Context Window Length\n",
    "The context window length of an embedding model is the number of surrounding words or context that are taken into account when generating the embedding for a certain word."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815e3745",
   "metadata": {},
   "source": [
    "#### How Retrieval Augmented Generation (RAG) works?\n",
    "Steps are below\n",
    "1. You have a user query that asks a specific question\n",
    "2. You have which you have previously embedded and stored in the retrieval system\n",
    "3. You take your query, run it through same embedding model you used to embed previous document and generate an embedding of the query\n",
    "4. The retrieval systems finds the most relevant documents according to the embedding of that query (the nearest neighbor documents for that embedding)\n",
    "5. Return both the query and the relevant documents to the LLM\n",
    "6. LLM synthesizes information from the retrieved document to generate an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ce72cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
